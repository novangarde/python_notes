Программная библиотека на языке Python, предназначенная для обработки и анализа структурированных данных. Она особенно полезна для работы с табличными данными, такими как CSV-файлы или Excel-таблицы.

**DataFrame** — это одна из основных структур данных в библиотеке pandas, предназначенная для работы с табличными данными. Его можно представить как двумерную таблицу, аналогичную таблицам в базах данных или листам в Excel.

```Python
import pandas as pd
data = {
    'Имя': ['Анна', 'Борис', 'Виктор'],
    'Возраст': [28, 34, 29],
    'Город': ['Москва', 'Санкт-Петербург', 'Новосибирск']
}
df = pd.DataFrame(data)
```

Существует множество методов для работы с DataFrames. Разберем основные:
### pd.read_csv

Метод для чтения файлов формата .csv, файлов, в которых столбцы отделены между собой табуляцией. Пример:

```Python
import pandas as pd

filepath = "../data/feed-views.log"

df = pd.read_csv(filepath, skiprows=[2, 3], skipfooter=2, engine='python', header=None, names=['datetime', 'user'])

# skiprows - пропускает строки под индексами 2 и 3 (в нашем примере)

# skipfooter - пропускает последние две строки (в нашем случае)

# engine='python' - указываем движок `Python`, потому что когда вы используете аргументы `skiprows` и `skipfooter`, Python-движок часто является обязательным для корректной работы этих функций. Это связано с тем, что движок Python позволяет более гибко обрабатывать строки и футер.

# header=None, names=['date_time', 'user'] - указывает на отсутствие заголовков в файле и сразу добавляет их в виде `date_time` и `user`.
```

После прочтения файл сохраняется в переменную `df`, с которой мы дальше можем работать, изменяя заголовки, назначая индексы и т.д.

> Также при чтении файла может понадобиться указать параметр `sep='\t'`, чтобы метод разделил колонки по разделителю, иначе вся строка может попасть в одну колонку. 

### df.set_index()

Вернемся к примеру выше и установим одну из колонок в качестве индекса

```Python
df.set_index('datetime', inplace=True)

# Устанавливает колонку datetime индексной колонкой.

# Параметр `inplace=True` означает, что метод изменяет исходный DataFrame напрямую без создания нового объекта. Если вы не используете параметр `inplace=True`, метод возвращает новый измененный DataFrame, а исходный остается неизменным.
```

После установления столбца `dataframe` индексным, этот столбец становится индексом DataFrame. После этого вы можете обращаться к значениям по ключу из индексной колонки.

### df.reset_index()

Если какая-либо колонка установлена в качестве индекса, ее нельзя переименовать. Поэтому сначала придется снять индекс при помощи `reset_index()`

```Python
df.reset_index(inplace=True)

# inplace=True означает, что метод изменяет исходный DataFrame напрямую без создания нового объекта.
```

### df.rename()

При помощи этого метода мы можем изменять название колонок

```Python
df.rename(columns={'datetime': 'date_time'}, inplace=True)

# inplace=True означает, что метод изменяет исходный DataFrame напрямую без создания нового объекта.
```

Если колонка установлена индексом, изменить ее не получится. Придется сначала использовать метод [[#df.reset_index()]], затем переименовать и потом снова установить индекс при помощи [[#df.set_index()]].

### df.drop_duplicates()

Используется для удаления дубликатов строк из DataFrame. Он позволяет оставить только уникальные комбинации значений в указанных столбцах.

```Python
df.drop_duplicates(subset=['CarNumber', 'Make_n_model', 'Fines'], keep='last')

# subset содержит список колонок, в которых нужно удалить дубликаты
# keep='last' устанавливает правило, что при удалении сохраняем последний дубль
```

### df.to_csv()

Объект pandas можно сохранить в .csv формате и сразу установить разделитель

```Python
df.to_csv('output.csv', sep=';')

# Параметр sep (separator) - устанавливает разделитель между колонками
```

### df.to_excel()

```Python
df.to_excel('ваш_файл.xls', index=False)
```

### pd.to_datetime()

Этот метод преобразует выбранный столбец в формат `datetime64[ns]`, формат даты и времени, принятый в Pandas и NumPy:

```Python
df['datetime'] = pd.to_datetime(df['datetime'])

# df['datetime'] указывает на нужный столбец в объекте
```

После преобразования мы можем создать в объекте новые столбцы, присваивая им значение из вложенного объекта dt и соответствующего атрибута:

```Python
df['year'] = df['datetime'].dt.year
df['month'] = df['datetime'].dt.month
df['day'] = df['datetime'].dt.day
df['hour'] = df['datetime'].dt.hour
df['minute'] = df['datetime'].dt.minute
df['second'] = df['datetime'].dt.second
```

### pd.cut()

Функция в библиотеке Pandas, которая используется для разделения непрерывных числовых данных на дискретные интервалы или категории. Она позволяет преобразовать непрерывные переменные в категориальные, что может быть полезно для анализа данных, создания гистограмм или сегментации пользователей.

#### Основные параметры и возможности:

- **bins**: Определяет границы интервалов. Может быть массивом чисел или количеством равных интервалов.
- **labels**: Присваивает метки каждому интервалу.
- **right**: Указывает, включать ли правую границу каждого интервала (по умолчанию `True`).
- **include_lowest**: Позволяет включить самую низкую точку в первый интервал (по умолчанию `False`).

#### Пример

```Python
bins = [0, 4, 7, 11, 17, 20, 24]

labels = ['night', 'early morning', 'morning', 'afternoon', 'early evening', 'evening']

df['daytime'] = pd.cut(df['hour'], bins=bins, labels=labels)
```

В этом примере, данные колонки hour будут разбиты на интервалы от 0 до 3, от 4 до 6, от 7 до 10, от 11 до 16, от 17 до 19, от 20 до 23 при помощи `bins`

Затем, при помощи `labels` каждому из интервалов присвоится нужное значение и сохранится в новую колонку `daytime`.

### df.count()

Используется для подсчета количества не пропущенных значений в каждом столбце DataFrame. Он игнорирует пропущенные значения

```Python
df.count()
# выводит количество значений в каждом столбце
```

### df.value_counts()

Используется для подсчета частоты каждого уникального значения в Series или столбце DataFrame. Он возвращает Series, где индексами являются уникальные значения из исходных данных, а значениями — количество раз, когда каждое из этих значений встречается.По умолчанию результаты сортируются по убыванию частоты (самые часто встречающиеся значения первыми). Пропущенные значения исключаются из результата по умолчанию.

```Python
df["column"].value_counts()
# Возвращает уникальные значения из колонки "column" с количеством их вхождений
```

### df.sort_values()

Используется для сортировки DataFrame или Series по значениям в указанном столбце или столбцах. Он позволяет сортировать данные как по возрастанию, так и по убыванию.

```Python
df.sort_values(by=['hour', 'minute', 'second'], ascending=[True]*3, inplace=True)

# сортирует по часам, минутам и секундам, по возрастанию
# вместо ascending=[True]*3 может быть ascending=[True, True, True] - в таком формате понятнее, как сортировать по разным столбцам
```

### df.loc()

Метод позволяет доступаться к строкам и столбцам DataFrame по их меткам или логическим условиям. Он является основным инструментом для индексации на основе меток.

### df.nsmallest()

Возвращает n самых маленьких значений из указанной колонки.

```Python
df.nsmallest(3, columns='hour')
# вернет три самых маленьких значения из колонки hour
```

Возможен и комбинированный вариант:

```Python
earliest_df = df[(df['daytime'] == 'morning')].nsmallest(3, columns='hour')[["hour"]]

# в earliest_df сохранится ттри самых маленьких значения из колонки hour, но будет выведена только индексная колонка и колонка "hour" с заголовком.
```

### df.nlargest()

Возвращает n самых больших значений из указанной колонки.

```Python
df.nlargest(3, columns='hour')
# вернет три самых больших значения из колонки hour
```

Комбинированный вариант:

```Python
latest_df = df[(df['daytime'] == 'morning')].nlargest(3, columns='hour')[["hour"]]

# в earliest_df сохранится три самых больших значения из колонки hour, но будет выведена только индексная колонка и колонка "hour" с заголовком.
```

### .df.describe()

Используется для генерации сводной таблицы с основными статистическими показателями для числовых столбцов DataFrame.

Пример:

```Python
stats = df['hour'].describe()
print(f"Basic statistics:\n{stats}")

# вернет статистические показатели по колонке hour
```

Статистика от `describe()`:

| Значение | Описание                                          |
| -------- | ------------------------------------------------- |
| count    | количество значений в колонке                     |
| mean     | медианное значение                                |
| min      | минимальное                                       |
| 25%      | значение на рубеже первого и второго квартиля     |
| 50%      | значение на рубеже второго и третьего квартиля    |
| 75%      | значение на рубеже третьего и четвертого квартиля |
| max      | максимальное                                      |

### df.isnull() || df.isna()

Проверяет, является ли ячейка пустой. Если да, возвращает True, если нет - False

```Python
df.isnull()
# Вернет таблицу, заполненную True/False значениями
```

Может быть использована для подсчета количества пустых ячеек, если применить вместе с `sum()` (не сработает с `count()`, который просто посчитает количество строк с True/False, поэтому вернет всю длину таблицы):

```Python
df.isnull().sum()
# вернет количество пустых ячеек в каждом столбце (суммирует True)
```

### df.dropna()

Используется для удаления строк или столбцов из DataFrame, содержащих пропущенные значения (NaN/NA)

```Python
df = df.dropna(axis=1, thresh=len(df)-500)
# axis - по умолчанию 0, удаляет строки, если поставить 1 - столбцы
# thresh - указывает минимальное число заполненных ячеек, которому должна соответствовать аггрегация, чтобы колонку не удалили. В данном примере, мы из длины таблицы вычитаем 500, то есть, удаляем все колонки, в которых больше 500 пустых ячеек.
```

### df.fillna()

Используется для заполнения пропущенных значений (NaN/NA) в DataFrame или Series

```Python
df['Refund'] = df['Refund'].fillna(method='ffill')
# method='ffill' (forward fill) означает, что ячейка будет заполнена значением из предыдущей ячейки. Можно просто указать df.fillna(0), чтобы заменить все на 0. Можно заменить на bfill (backward fill)
```

