

## 1. Первичный анализ данных

Крутим датасет при помощи [[Pandas]].

## 2. Очистка данных

### Преобразование категориальных признаков

#### Бинарные

Там, где значения `'yes'/'no'`, просто заменяем на `1/0`, остальное - с помощью `OneHotEncoder()`

#### Не бинарные

Используем `OneHotEncoder()`. К примеру, есть столбец "мебель в квартире", который может содержать один из трех вариантов:
* Меблированная
* Немеблированная
* Частично меблированная

Если применить `OneHotEncoder()`, он создаст три бинарных столбца со значениями `1/0` на базе имеющейся не бинарной категориальной колонки:
* Меблированная
* Немеблированная
* Частично меблированная

С такими данными уже может работать машина.

### Преобразование числовых признаков

#### Масштабирование (скалирование)

Масштабирование — это важный этап предобработки данных в машинном обучении и анализе данных. Оно заключается в преобразовании признаков (функций) так, чтобы они находились в одном и том же диапазоне или имели определенные статистические свойства и оказывали одинаковое влияние на модель.

**Стандартизация**

В этом коде используется **стандартизация** (standardization) для масштабирования количественных признаков. Это достигается с помощью класса `StandardScaler` из библиотеки `sklearn`:

```Python
scaler1 = StandardScaler()

X1_numeric = pd.DataFrame(
    scaler1.fit_transform(X1[var_numeric]),
    columns=var_numeric
)

scaler2 = StandardScaler() # ваш код здесь

X2_numeric = pd.DataFrame( # ваш код здесь
    scaler2.fit_transform(X2[var_numeric]),
    columns=var_numeric
)
```

Формула стандартизации
$$Z = (x - \mu) / \sigma$$
где:
$z$ - стандартизированное значение
$x$ - исходное значение признака
$\mu$ - среднее значение признака
$\sigma$ - стандартное отклонение признака

## 3. Разделение данных на тренировочные и тестовые

## 4. Регуляризация

В каждой модели есть свои методы регуляризации. К примеру

## 5. Метрики

Основные метрики для анализа результативности модели